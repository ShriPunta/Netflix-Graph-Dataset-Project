{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ParsingTheCombinedFile.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ShriPunta/Netflix-Graph-Dataset-Project/blob/master/ParsingTheCombinedFile.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "MfY3KTxwcuzj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7QxpoHbSL7hr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install python-igraph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F5hsv8FRc6yo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Setup all the Authentication for PyDrive**"
      ]
    },
    {
      "metadata": {
        "id": "se2OMKeGcyTB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from googleapiclient.discovery import build\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vm_wC5htdbEo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "82YemEDEdRGh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HoWP4dWD47m3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "44rkbJ-TAySS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Method to combine all the records**"
      ]
    },
    {
      "metadata": {
        "id": "WW_LCEL5-e4g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def merge_all_texts(file_list):\n",
        "  import shutil\n",
        "\n",
        "  with open('AllMerged.txt','wb') as wfd:\n",
        "    for f in [file_list]:\n",
        "      with open(f,'rb') as fd:\n",
        "        shutil.copyfileobj(fd, wfd, 1024*1024*10)\n",
        "        #10MB per writing chunk to avoid reading big file into memory."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CYp7ZjbubqF2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "** *Method*: To read the contents of a local Google File**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "E2xhw0Cjk1Cs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_drive_file_into_variable(file_id_to_read):\n",
        "  drive_service = build('drive', 'v3')\n",
        "  request = drive_service.files().get_media(fileId=file_id_to_read)\n",
        "  downloaded = io.BytesIO()\n",
        "  downloader = MediaIoBaseDownload(downloaded, request)\n",
        "  done = False\n",
        "  while done is False:\n",
        "    # _ is a placeholder for a progress object that we ignore.\n",
        "    # (Our file is small, so we skip reporting progress.)\n",
        "    status, done = downloader.next_chunk()\n",
        "    prog = int(status.progress() * 100)\n",
        "    print(\"Download \"+str(prog))\n",
        "  \n",
        "  #Set the pointer to the start\n",
        "  downloaded.seek(0)\n",
        "  #print('Downloaded file contents are: {}'.format(downloaded.read()))\n",
        "  \n",
        "  #Read Everthing into a variable called \"View\", its in a \"Bytes\" datatype\n",
        "  view = downloaded.read1(-1)\n",
        "  #len(view)\n",
        "  \n",
        "  #decode Bytes to String format\n",
        "  decoded = view.decode(encoding=\"utf-8\")\n",
        "  #type(decoded)\n",
        "  \n",
        "  #Convert this continous string to List for each new line\n",
        "  variable_to_set = decoded.splitlines()\n",
        "  #type(splitted)\n",
        "  \n",
        "  return variable_to_set\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y_NHUDFt5qLm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "Wde9XWULuQOo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Read the main two files into variables**"
      ]
    },
    {
      "metadata": {
        "id": "l53Y5UuvlTA0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movie_Title_file_id = '0B8qgJkz0ynl8czBBNG9qZ2JPeW9RaWVuZktobUE1b29qaER3'\n",
        "part_rating_file_id = '1iABtudmoCPxcFYiYQ0cQwfcQCZtfHsHd'\n",
        "test_file_id = '11QhP0HwV7x6huJX3-JqJzGv7shMiZVPH'\n",
        "merged_file_id = '1zhm2Wo8qBun5p01z_hjZlkww1TIbkTJy'\n",
        "merge_first3_files = '1R8g2MWa1Czpzt7EAGUfcvADJ-yIB2Yi9'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hauotqIq69LL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "key_file_list = read_drive_file_into_variable(movie_Title_file_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mft79xExZKZq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "merged_file3_list = read_drive_file_into_variable(merge_first3_files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6NT8R1EVBLLN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#merged_file_list = read_drive_file_into_variable(merged_file_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fwZbBuv66-Y6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#rating_file_list = read_drive_file_into_variable(part_rating_file_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VBfmPUyH7xn8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#test_file_list = read_drive_file_into_variable(test_file_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LNwdzKOEBcNm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final_file_list_to_use = merged_file3_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PLPYJKQ-4_ba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "BO6_CVlAmsgT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Convert the key file into a dataframe**"
      ]
    },
    {
      "metadata": {
        "id": "E-EXS8ZvduXq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Read the key file into a Panda dataframe\n",
        "key_file_df = pd.DataFrame([sub.split(\",\") for sub in key_file_list],columns = [\"MovieId\",\"Year\",\"Name\",\"Genre1\",\"Genre2\",\"Genre3\"])\n",
        "\n",
        "key_file_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o2i-iRXssIUc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "key_file_df.info(memory_usage = 'deep')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8QVL-b855fy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Clean the dataframe**"
      ]
    },
    {
      "metadata": {
        "id": "My_tjoVRm3nJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#key_file_df['Genre'] = key_file_df[['Genre1','Genre2','Genre3']].apply(lambda x: ''.join(x), axis=1)\n",
        "# key_file_df.head()\n",
        "\n",
        "def clean_the_movie_key_df(key_file_df):\n",
        "  #Convert NaN to blank\n",
        "  key_file_df = key_file_df.replace(np.nan, '', regex=True)\n",
        "    \n",
        "  #Combine the Genres into a single column\n",
        "  key_file_df['Genre'] = key_file_df['Genre1'] + ',' + key_file_df['Genre2'] + ','+ key_file_df['Genre3']\n",
        "  \n",
        "  \n",
        "\n",
        "  #Clean the column by removing double quotes; Also converts to string\n",
        "  key_file_df['Genre'] = key_file_df['Genre'].str.replace('\"', '')\n",
        "\n",
        "  #Drop the unnecessary columns\n",
        "  key_file_df.drop(['Genre1','Genre2','Genre3'], axis=1, inplace=True)\n",
        "  \n",
        "  #Convert to numeric\n",
        "  key_file_df['MovieId'] = pd.to_numeric(key_file_df['MovieId'],errors = 'coerce')\n",
        "  \n",
        "  #Convert to numeric\n",
        "  key_file_df['Year'] = pd.to_numeric(key_file_df['Year'],errors = 'coerce')\n",
        "  \n",
        "  #Convert to String\n",
        "  key_file_df['Name'] = key_file_df['Name'].astype('str')\n",
        "  \n",
        "  \n",
        "  #Set MovieId as the Index\n",
        "  key_file_df.set_index('MovieId',inplace=True)\n",
        "  \n",
        "  #Drop any rows which NaN or NULL\n",
        "  key_file_df.dropna(axis=0, how='any',inplace=True)\n",
        "\n",
        "  return key_file_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dXL_tT4DhaEf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "key_file_df = clean_the_movie_key_df(key_file_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2fWLk6Du_0mL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Gives detailing on how many null or na there are\n",
        "key_file_df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p4Qhf6g2kyE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "key_file_df.info(memory_usage='deep')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Qei-rqObwld",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** We store the index(which are the movie Ids) as a list; to be used as a reference later**"
      ]
    },
    {
      "metadata": {
        "id": "oN1iebJG2m4C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "key_movie_values = key_file_df.index.values\n",
        "key_movie_values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "opsRfxs151Ca",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "xIiOw39e7VF5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create a Map of each movie with the number of ratings it has**"
      ]
    },
    {
      "metadata": {
        "id": "7_L9iQDGyjvM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fill_dict_count(list_to_iterate):\n",
        "  each_movie_votes = dict()\n",
        "  for ele in list_to_iterate:\n",
        "    if ele.find(':') != -1:\n",
        "      key_to_search = (ele.split(':'))[0]\n",
        "      \n",
        "      #Get a map of how many ratings are there per movie\n",
        "      each_movie_votes[key_to_search] = 0\n",
        "    else:\n",
        "      each_movie_votes[key_to_search] +=1\n",
        "   \n",
        "  return each_movie_votes\n",
        "      \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qdzz8dT0cDjS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**---> PARSNG and SAMPLING <---**\n",
        "\n",
        "**SAMPLING  : It takes the 23 million ratings, and only keeps limited number of ratings per movie (This is controlled by the 'limiter' variable).**\n",
        "\n",
        "**We only want values whose genre we have, hence we weed out those movies, who are not present in the movie_Title_file**\n",
        "\n",
        "**----**\n",
        "  \n",
        "**PARSING :  It also adds a comma separated value of the movie id to the tuple. (It is split later to create a dataframe).**"
      ]
    },
    {
      "metadata": {
        "id": "AgqW-cc2TJR4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def do_sampling(list_to_iterate,file_rating_dict):\n",
        "  flag=True\n",
        "  percent = 0.5\n",
        "  count = 0\n",
        "  refined_list = []\n",
        "  key_to_search = 0\n",
        "  limiter = 1\n",
        "    \n",
        "  for ele in list_to_iterate:\n",
        "    \n",
        "    #If the element has a ':' then its a movie id\n",
        "    if ele.find(':') != -1:\n",
        "      count = 1\n",
        "      #we will remove the ':' from the tuple\n",
        "      #This is done as we can then successfully apply the pd.to_numeric method to drastically reduce the dataframe size\n",
        "      key_to_search = (ele.split(':'))[0]\n",
        "      \n",
        "      #We want only those movies which are present in the movie_Title_file\n",
        "      if int(key_to_search) in key_movie_values:\n",
        "        #If this movie is present, set flag as true\n",
        "        flag = True\n",
        "        \n",
        "        #Set Limiter value\n",
        "        limiter = round(file_rating_dict.get(key_to_search) * percent)\n",
        "      else:\n",
        "        flag = False\n",
        "    else:\n",
        "      #If the flag is false(i.e. movie not found) or if the count more than the limit; SKIP the record\n",
        "      if count > limiter or flag is False:\n",
        "        continue\n",
        "      #Add a comma separated value of the movieId to split and form a column later\n",
        "      refined_list.append(ele+','+ str(key_to_search))\n",
        "      count+=1\n",
        "      \n",
        "  return refined_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "216xjh6Sy_wy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "count_strength = fill_dict_count(final_file_list_to_use)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YvjC0ZyaBchp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "refined_list = do_sampling(final_file_list_to_use,count_strength)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zx9HLeiKw_GC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_values = sorted(set(count_strength.values()),reverse=True)\n",
        "print(max_values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VomO7IUG2Zvd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(len(count_strength.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zGaNXLEOfypn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Get a judgement of the size of the earlier list and size after sampling**\n"
      ]
    },
    {
      "metadata": {
        "id": "dw-TQ_k0FLax",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sys import getsizeof\n",
        "#print(\"Total number of elements -->\",len(rating_file_list),\"  Size they occupy in bytes -->\",getsizeof(rating_file_list))\n",
        "\n",
        "print(\"Total number of Elements in rating_file_list list -->\",len(final_file_list_to_use),\"  Size they occupy in bytes -->\",getsizeof(final_file_list_to_use))\n",
        "print(\"Total number of Elements in refined_list list -->\",len(refined_list),\"  Size they occupy in bytes -->\",getsizeof(refined_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rtt_MMsvBdtq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "iwy5JBQSyn5k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Convert rating File into dataframe**"
      ]
    },
    {
      "metadata": {
        "id": "d2WdF9TVy4XB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Read the key file into a Panda dataframe\n",
        "test_file_df = pd.DataFrame([sub.split(\",\") for sub in refined_list],columns = [\"UserId\",\"Rating\",\"YearWatched\",\"MovieId\"])\n",
        "\n",
        "#Initialize a blank column called MovieId ; to be filled latter\n",
        "test_file_df[['MovieId']] = test_file_df[['MovieId']].apply(pd.to_numeric)\n",
        "\n",
        "#Need memory optimization, convert the object type to numeric\n",
        "test_file_df[['UserId']] = test_file_df[['UserId']].apply(pd.to_numeric)\n",
        "\n",
        "#Need memory optimization, convert the object type to numeric\n",
        "test_file_df[['Rating']] = test_file_df[['Rating']].apply(pd.to_numeric)\n",
        "\n",
        "#Convert the column to datetime and keep only the year\n",
        "test_file_df['YearWatched'] = pd.to_datetime(test_file_df['YearWatched']).dt.year\n",
        "\n",
        "#Need memory optimization, convert the object type to numeric\n",
        "test_file_df['UserId'] = pd.to_numeric(test_file_df['UserId'],errors='ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y_Zk5MTQz6jo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Applying these changes in datatypes brought memory usage from 5.4 GB to 2 GB\n",
        "test_file_df.info(memory_usage = 'deep')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W9YGhC20voIX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Drop any rows which NaN or NULL\n",
        "test_file_df.dropna(axis=0, how='any',inplace=True,thresh = 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kTODJAuXBBi0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_file_df.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C-fqEv2XWxqG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create a matrix which is the same size of test_file_df matrix, but instead has True/False about which if the value is NaN\n",
        "the_NaN_matrix = test_file_df.isnull().sum()\n",
        "the_NaN_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LjGeWxPA8qlX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_file_df['Genre'] = ''\n",
        "\n",
        "\n",
        "#Copy the Genre Column from key file pandas dataframe\n",
        "test_file_df['Genre'] = test_file_df['MovieId'].map(key_file_df['Genre'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CqqdGAhy8q0c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#To download the Panda Data Frame\n",
        "#test_file_df.to_csv('test_file_df.csv',index=False)\n",
        "#files.download('test_file_df.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nR_wNZebGPl_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nM4AsBNy6dM9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        " ** *Method*: To see the GPU usage**"
      ]
    },
    {
      "metadata": {
        "id": "KEGfc73g0Zb0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def checkGPU():\n",
        "  # memory footprint support libraries/code\n",
        "  !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "  !pip install gputil\n",
        "  !pip install psutil\n",
        "  !pip install humanize\n",
        "  import psutil\n",
        "  import humanize\n",
        "  import os\n",
        "  import GPUtil as GPU\n",
        "  GPUs = GPU.getGPUs()\n",
        "  # XXX: only one GPU on Colab and isn’t guaranteed\n",
        "  gpu = GPUs[0]\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7x3m84Vo6eyl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "CF668Mtx6hVz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkGPU()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9DD1IQwVl776",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## **CODE GRAVEYARD**"
      ]
    },
    {
      "metadata": {
        "id": "wekTAtVMl9SC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "WpeP4ACi_Wui",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#This Method gives the Numpy shape error; reason unidentified\n",
        "\n",
        "# def do_sampling(list_to_iterate):\n",
        "#   flag=True\n",
        "#   #Limiter variable\n",
        "#   limiter = 100\n",
        "#   count = 0\n",
        "#   #variable to be returned\n",
        "#   refined_list = []\n",
        "#   key_to_search = 0\n",
        "#   movieId_to_search=''\n",
        "#   for ele in list_to_iterate:\n",
        "#     #If the element has a ':' then its a movie id\n",
        "#     if ele.find(':') != -1:\n",
        "#       count = 1\n",
        "#       #we will remove the ':' from the tuple\n",
        "#       #This is done as we can then successfully apply the pd.to_numeric method to drastically reduce the dataframe size\n",
        "#       movieId_to_search = ele.replace(':','')\n",
        "#       #We want only those movies which are present in the movie_Title_file\n",
        "      \n",
        "#       if movieId_to_search in key_movie_values:\n",
        "#         print('found')\n",
        "#         #If this movie is present, set flag as true\n",
        "#         flag = True\n",
        "#         refined_list.append(movieId_to_search)\n",
        "#       else:\n",
        "#         flag = False\n",
        "#     else:\n",
        "#       #If the flag is false(i.e. movie not found) or if the count more than the limit; SKIP the record\n",
        "#       if count > limiter or flag is False:\n",
        "#         continue\n",
        "#       #Add a comma separated value of the movieId to split and form a column later\n",
        "#       ele += ',' +str(movieId_to_search)\n",
        "      \n",
        "#       refined_list.append(ele)\n",
        "      \n",
        "#       count+=1\n",
        "#   return refined_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1S3P-_LKvX_J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**BELOW 2 blocks have been deemed deprecated **"
      ]
    },
    {
      "metadata": {
        "id": "wodMLOJ71N8t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "4BCjU0aIZR01",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Ultra fast method to get the indexes of the rows we need to drop; Reduces time from a minute to a second\n",
        "#For records which only had the movie id and nothing else, will have NaN for columns other than the first column\n",
        "#fancy_list = test_file_df[the_NaN_matrix['Rating'] == True].index.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cwCM-TtfArBp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#type(fancy_list[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wfrIWbVNFPr_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**This below block is deprecated, due to the faster and optimized ways.**"
      ]
    },
    {
      "metadata": {
        "id": "fNaA0ToZ8qjC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #We will store the rows to drop in this\n",
        "# rows_to_drop = []\n",
        "# currentMovieId = 0\n",
        "# list_movieId = []\n",
        "\n",
        "\n",
        "# #Iterate over the dataframe to split it\n",
        "# for index, row in test_file_df.iterrows():\n",
        "#   if the_NaN_matrix.iloc[index,2]:\n",
        "#     #If entered it means that there is a colon on the row and it is a movie id\n",
        "#     #row gives the first character on that row\n",
        "#     #currentMovieId = row['UserId']\n",
        "#     rows_to_drop.append(index)\n",
        "#   else:\n",
        "#     list_movieId.append(currentMovieId)\n",
        "#     #print(\"Not\")\n",
        "#     #Assign the movie id to the consecutive rows\n",
        "#     #test_file_df.iloc[index,3] = currentMovieId\n",
        "\n",
        "# #Create a series object from the list\n",
        "# #MovieIdSeries = pd.Series(list_movieId)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hRGTQCNogdNu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9ejn_If9ZDCQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Drop the rows which had the movie Id and the columns to get a seamless dataframe\n",
        "#test_file_df.drop(test_file_df.index[fancy_list],inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bl4jexwJviN-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wPFakwQkvi3e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}